## Kubernetes training

# 1. Kubernetes architecture:
 -  Kubernetes = an open-source system for automating delpoyment, scaling and managemnt of containerized applications
 -  Kubernetes relies on the assumption that it will operate on a large number of small independent services (microservices) rather than on a monolith app
 -  Chaos Monket = would users notice if you terminate any container randomly? If so, it may men that you app should be more decoupled and transient
 -  cgroups and namespaces are the heart of containers, including Docker
 -  Kuberbetes is made of one or more central managers and worker nodes
     - API server serves responses from clients like kubectl or any custom implementation
     - kube-scheduler sees the API requests for running a new container and finds suitable node to run that container 
     - each node in a cluster has two containers:
        - kubelet: manages resources and container engine (Docker engine that is installed on all the nodes) to ensure the container runs and restarts as expected. Takes Pod specifications as the input and tends to satisfy the requirements that are stated
        - kube-proxy: container creates and manages local firewall and handles communiaction between containers 
     - pod: smallest unit to work with, consists of one or more containers which share IP, data volumes and network namespace (typically we have one container for app and some containers supporting primary app). The *pause container* is placed in the pod to provide IP address, all containers in a pod will use its network namespace (it's not visible from k8s perspective). Containers can communicate via loopback interface, writing to files or via inter-process communication. 
     Containers in a pod are started in parallel by default. 
     - orchestration is managed via operators:
        - *Deployment* operator: deployes and manages *ReplicaSet* operator
        - *Replica Set* operator: deploys multiple pods, each with the same spec 
        - *DeamonSet*: ensure that a single pod is deployed on every node (used for loggin, metrics, security)
        - *StatefulSet* ensures that pods are started in specified order
        - *label* are used by *selectors* to fetch some object without knowing their IDs
     - isolation mechanisms:
        - namespace: segregation of resources
        - context: combination of user, cluster and namespace
        - resource limits: a way to limit the amount of resources consumed by a pod
        - Pod Security Admission
        - Network Policies: the ability to have an inside-the-cluster firewall
     - Control Plane Node Components:
        - *kube-apiserver*: acts as a master process of a cluster, also as a frontend to the cluster's shared state, is the only one that connects to *etcd*
        - *kube-scheduler*: selects which node will host a pod of containers (can have different algorithms for that), when there is no cluster space with requested specification the pod will remain pending 
        - *etcd*: keps the state of the cluser, networking and other persistent information
        - kube-controller-manager: core control loop deamon which interacts with the kube-apiserver to determine the state of the cluster 
        - *Services* operator which connects resources together, also reconnect and replace what needed. Handles access policies for inbound requests
        - *Operators* known as watch-loops, theu query current state, compare that against the spec and execute code based on how they differ
    - *networking*:
        - three main networing challenges:
            - container-to-container communication (solved by the pod concept)
            - pod-to-pod communication, the *Service* object is used to connect Pods within the network using ClusterIP adress, from outside of the cluster using NodePort address. 
            - external-to-pod communication
        - ClusterIP is used for traffic within the cluster
        - NodePort: first creates a ClusterIP, then associates a port of the node to that new ClusterIP
    - CNI network configuration file - used to standarize networking

# 2. Build
 - multicontainer pod terminology:
    - ambassador: secondary container used to communicate with outside resources, often outside the cluster
    - adapter: useful to modify the data generated by the promary container
    - helps or provides a service not found in the primary application, e.g logging containters are common sidecar
 - probes:
    - readinessProbe: our application may have to initialize or be configured prior to being ready to accept traffic, the container will not accept traffic until the probe return a healthy state
    - livenessProbe: used to ensure that container stays in a healthy state, if probe fails the container will be terminated
    - startupProbe: useful for testing an application which takes a long time to start, liveness and readiness checks are disabled unitl the application passes the test

# 3. Desing
 - decoupled resources
 - transience
 - managing resource usage:
    - by default, pods use as much CPU and memory as the workload requires
    - CPU:
        - units are milicore, .7 of CPU is 700 milicores
        - if container uses more resources than allowed it is throttle 
        - limits can be set to pod or container, if limit is set to pods all containers are throttled in the same time
    - memory:
        - handling of container which exceedes its memory limit is not defined: may be restarted or the enitre Pod can be evicted from the node
    - storage: 
        - pod that uses more storage than declared and available on the node can be evicted
 - label selectors:
    - labels: key/value pairs that are attached to objects such as Pods, used to specify identifying attributes of objects. Labels can be used to organize and select subsets of objects. Labels do not provide uniqueness, we expect many objects to carry the same lables
    - label selector: allow user to identify set of objects
 - multi-container pods:
    - sidecar: used to add some functionality not present in the main container without bloating code, e.g logger
    - adapter: used to modify input or output of main container, e.g to adapt logs produced by main container to monitoring tool (to achieve standarization between multiple apps)
    - ambassador: allows to access to the ourside world without having to implement a service or another entry in an ingress controller
    - initContainer: allows container to start only if "init" container exited successfully, eg. security scan of container before starting it
- jobs:
    - can be used when the microservice needs not to run all the time
    - run a pod to completion
    - Cronjobs

# 4. Deployment configuration
 - volumes:
     - volume is directory, possibly pre-populated, made available to containers in a Pod
     - 28 different volume types
     - Persistent Volumes = storage lifetime distinct from a Pod 
     - the same volume can be used by different containers = we can achieve pod to pod communication in such a way (no locking options available)
     - *emptyDir* = kubelet will create the directory in the container, but not mount any storage, in result we obtain non persistent storage
     - *hostPath* = mounts a resource from the host node filesystem
     - secrets: 
        - by default are not encrypted but encoded with base64, encryption can be added via *EncryptionConfiguration*
        - can be exposed as a env variable or mounted volume
     - configMaps:
        - similar to Secrets but not encoded
        - can store key-value pairs or plain configuration files in any format (file data stored in *data* section)
    - both secrets and configMaps must exist prior to being used by a Pod (unless marked as optional)

# 5. Security
 - connections to Kubernetes API are protected with TLS
 - access control layers:
    - authentication
        - done via: certificates, tokens or basic authentication
        - support for system accounts
    - authorization
    - admission control: piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object. May be validating, mutating or both. 
- pods and container within pods can be given specific security constraints to limit what processes running in containers can do (Linux capabilities, filesystem group, etc.)
- security limitations are called security context, it an be defined for the entire pod or per container. In such a rule you can specify for example that containers cannot run their process as the root user. 
- PSP (Pod Security Policies): cluster-level rules that govern what a pod can do, what they can access or what user they run as. For example, we can define rule that any container in the cluster cannot run as a root. 
- An alternative to PSP is to use OPA (Open Policy Agent) that can run as admission controller. 
- Pod Security Standards: there are three main policies to limit what a pod is allowed to do:
    - privileged
    - baseline
    - restricted
- Network Security Policies: 
    - by default, all pods can reach each other, all ingress and egress traffic is allowed
    - NetworkPolicy: enable to control traffic to the pods, allows to use for example node selectors and select IP addresses or ports

# 6. Exposing applications: 
 - Service type: 
    - *Cluster IP*: default service type, provides access internally, *kubectl proxy* creates a local service to access a ClusterIP
    - *NodePort*: is a simple connection from a high-port routed to a ClusterIP using iptables. The creation of NodePort generates a ClusterIP by default. Traffic is routed from the NodePort to the ClusterIP. Only high ports can be used. The NodePort is accessible via calls to *NodeIp:NodePort*
    - *Load balancer*: created to pass requests to a cloud provider, even without a cloud provider, the address is made available to public traffic, and packages are spread among the Pods in the deployment automatically. Creating a *LoadBalancer* service generates a *NodePort*, which then creates a *ClusterIP*. It also sends an asynchronous call to an external load balancer, typically supplied by a cloud provider. The *External-IP* value will remain in a *Pending* state
        until the load balaner return. Should it not return, the *NodePort* created acts as it would otherwise.
    - *ExternalName*: allows to return of an alias to an external service (point to an external DNS server).  
 - Services update pattern: 
    - labels are used to determine which pods should receive traffic from a service, labels can be dynamically updated for an object, which may affect which Pods continue to connect to a service
 - services can also be useed to point to a service in a different namespace, or even a resource outsie the cluster, such as a legacy application not yet in Kubernetes
 - Ingress Controller: introduced to simplify management when number of services becomes high, manages ingress rules to route traffic to existing services. Ingress can be used for fan out to services, name-based hosting, TLS, or load balancing. 
 - Service mesh: one can think about that as a proxy, side car container that is attached to original pod and manages things related to networking and communication like: security, discovery, circuit breakers, tracing, etc. This additional layer can be added independently to app layer (outside app container).  

# 7. Application trobleshooting
 - basic throubleshoooting steps:
    - pod/node logs
    - shell 
    - standard
    - linux tools are usefull in kubernetes problems investigation (e.g. for networking issues) 
    - check node healt, available resources
    - deploy sidecar container for logging purposes 
    - pods status (*kubectl get*)
    - check security constraints (e.g RBAC)
 - monitoring: collecting logs from the infrastructure
    - Prometheus: allows to scrape resource usage metrics from Kubernetes objects across the entire cluster, allows to implement alerting
    - Graphana: allows to visualize data retrieved via Prometheus
 - logging tools: 
    - collected locally, aggregated and then ingested into search engine or visualization tool (common toolset is ELK - Elastic, Logstash, Kibana)
    - *kubelet* writes logs to local files via the Docker logging driver
    - *Fluentd* can be used to aggregate logs cluster-wide (*Fluentd* agents run on each node via a DeamonSet, they aggregate the logs, and feed them to an Elasticsearch instance)
 - tracing:
    - allows for granular understanding of transaction across distributed architecture
    - examples of tools: OpenTracing/Jaeger
 - journal:
    - system and agent files location depends on existance of systemd, the ones with systemd logs to `journalctl` and can be found by `journalctl -a`. Unless `/var/log/journal` directory exists that journal is volatile. Without `systemd` lod will be created under `/var/log/<agent>.log`
